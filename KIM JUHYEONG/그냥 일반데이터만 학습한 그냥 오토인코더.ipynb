{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb177214",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\master\\anaconda3\\envs\\EDA\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "INFO:albumentations.check_version:A new version of Albumentations is available: 1.4.12 (you have 1.4.10). Upgrade using: pip install --upgrade albumentations\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import cv2\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "num_epochs = 50\n",
    "batch_size = 16\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 시드값 설정\n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, csv_file=None, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.csv_file = csv_file\n",
    "        self.transform = transform\n",
    "        if csv_file is not None:\n",
    "            self.df = pd.read_csv(csv_file)\n",
    "        else:\n",
    "            self.df = None\n",
    "        self.image_names = os.listdir(image_dir)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.image_names[idx]\n",
    "        img_path = os.path.join(self.image_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.df is not None:\n",
    "            label = self.df[self.df['ID'] == img_name]['target'].values[0]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image\n",
    "\n",
    "# 이미지 전처리 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "        \n",
    "\n",
    "# 오토인코더 모델 정의\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 32, kernel_size=2, stride=2),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "# GPU가 사용 가능한지 확인\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "autoencoder = Autoencoder().to(device)    \n",
    "\n",
    "# 테스트 데이터셋 로드\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.file_names = [f for f in os.listdir(root_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.file_names[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, self.file_names[idx]\n",
    "\n",
    "test_dataset = TestDataset(root_dir='cv_challenge/test', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# 결과를 저장할 폴더 생성\n",
    "output_dir = 'origin_denoising_AE'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# 모델 로드\n",
    "autoencoder.load_state_dict(torch.load('autoencoder_model_512.pth'))\n",
    "autoencoder.eval()\n",
    "\n",
    "# 테스트 데이터 노이즈 제거 및 저장\n",
    "with torch.no_grad():\n",
    "    for images, file_names in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = autoencoder(images)\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        for i, file_name in enumerate(file_names):\n",
    "            denoised_image = outputs[i].transpose(1, 2, 0)  # [C, H, W]에서 [H, W, C]로 변환\n",
    "            denoised_image = (denoised_image * 255).astype(np.uint8)  # [0, 1] 범위를 [0, 255]로 변환\n",
    "            denoised_image = np.clip(denoised_image, 0, 255)  # 값이 [0, 255] 범위 내에 있는지 확인\n",
    "            output_path = os.path.join(output_dir, file_name)\n",
    "            Image.fromarray(denoised_image).save(output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
