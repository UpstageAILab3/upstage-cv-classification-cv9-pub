{"cells":[{"cell_type":"markdown","metadata":{"id":"OliaDaX_lwou"},"source":["# **📄 Document type classification baseline code**\n","\n","**Contents**\n","- Prepare Environments\n","- Import Library & Define Functions\n","- Hyper-parameters\n","- Load Data\n","- Train Model\n","- Inference & Save File\n"]},{"cell_type":"markdown","metadata":{"id":"zkH9T_86lDSS"},"source":["# 1. Prepare Environments\n","\n","* 데이터 로드를 위한 구글 드라이브를 마운트합니다.\n","* 필요한 라이브러리를 설치합니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NC8V-D393wY4"},"outputs":[],"source":["#%%time\n","# 필요한 라이브러리를 설치합니다. 1분걸림\n","#%pip install timm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9X4xGu0eM19n"},"outputs":[],"source":["### 데이터 위치 셋팅\n","import os\n","os.chdir('/home')\n","\n","Train_path = 'data/' +  'train_2_45D'\n","Train_csv = 'csv/'+     'train_2_45D.csv'\n","\n","Test_path = 'data/' +   'test_final'\n","Test_csv = 'csv/' +     'sample_submission.csv'\n","\n","Model_path = 'model/'+  'Swin2_train_2_45D'"]},{"cell_type":"markdown","metadata":{"id":"PXa_FPM73R9f"},"source":["## 2. Import Library & Define Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kPqcJ-ENM19o","outputId":"48196b1c-ae99-4494-8b25-fa56d61b87cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["PyTorch version: 2.1.0\n","Is CUDA available: True\n","CUDA version: 11.8\n","cuDNN version: 8700\n","GPU name: NVIDIA GeForce RTX 3090\n"]}],"source":["import torch\n","\n","# PyTorch 버전 확인\n","print(f\"PyTorch version: {torch.__version__}\")\n","\n","# CUDA 사용 가능 여부 확인\n","print(f\"Is CUDA available: {torch.cuda.is_available()}\")\n","\n","# CUDA 버전 확인\n","if torch.cuda.is_available():\n","    print(f\"CUDA version: {torch.version.cuda}\")\n","\n","# cuDNN 버전 확인\n","print(f\"cuDNN version: {torch.backends.cudnn.version()}\")\n","\n","# GPU 이름 확인\n","if torch.cuda.is_available():\n","    print(f\"GPU name: {torch.cuda.get_device_name(0)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3BaoIkv5Xwa0"},"outputs":[],"source":["\n","import time\n","import random\n","\n","import timm\n","import torch\n","import albumentations as A\n","import pandas as pd\n","import numpy as np\n","import torch.nn as nn\n","from albumentations.pytorch import ToTensorV2\n","from torch.optim import Adam\n","from torchvision import transforms\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score, f1_score\n","import cv2\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bvaj9fEZvZLz"},"outputs":[],"source":["### 전역변수 설정\n","#home = '/content/drive/MyDrive/AILAB/CV/Contest/'\n","\n","#from google.colab import drive\n","#drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"laKUauMFu-rn"},"outputs":[],"source":["import gc\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5aAdT4q2JY_j"},"outputs":[],"source":["# 시드를 고정합니다.\n","SEED = 42\n","os.environ['PYTHONHASHSEED'] = str(SEED)\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","torch.backends.cudnn.benchmark = True"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hyl8oAy6TZAu"},"outputs":[],"source":["# 데이터셋 클래스를 정의합니다.\n","class ImageDataset(Dataset):\n","    def __init__(self, csv, path, transform=None):\n","        self.df = pd.read_csv(csv).values\n","        self.path = path\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        name, target = self.df[idx]\n","        img = np.array(Image.open(os.path.join(self.path, name)))\n","        if self.transform:\n","            img = self.transform(image=img)['image']\n","        return img, target"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kTECBJfVTbdl"},"outputs":[],"source":["# 학습을 위한 함수입니다.\n","def train_epoch(loader, model, optimizer, loss_fn, device):\n","    model.train()\n","    train_loss = 0\n","    preds_list = []\n","    targets_list = []\n","\n","    pbar = tqdm(loader)\n","    for image, targets in pbar:\n","        image = image.to(device)\n","        targets = targets.to(device)\n","\n","        model.zero_grad(set_to_none=True)\n","\n","        preds = model(image)\n","        loss = loss_fn(preds, targets)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())\n","        targets_list.extend(targets.detach().cpu().numpy())\n","\n","        pbar.set_description(f\"Loss: {loss.item():.4f}\")\n","\n","    train_loss /= len(loader)\n","    train_acc = accuracy_score(targets_list, preds_list)\n","    train_f1 = f1_score(targets_list, preds_list, average='macro')\n","\n","    ret = {\n","        \"train_loss\": train_loss,\n","        \"train_acc\": train_acc,\n","        \"train_f1\": train_f1,\n","    }\n","\n","    return ret"]},{"cell_type":"markdown","metadata":{"id":"Wjom43UvoXcx"},"source":["## 3. Hyper-parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KByfAeRmXwYk"},"outputs":[],"source":["# device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# model config\n","model_name = 'swinv2_base_window12_192' #swinv2_large_window12to24_192to384' # 'efficientnet_b5' #\n","\n","# 하이퍼파라미터를 설정합니다.\n","img_size = 192  #224 #크기를 늘리면 모델이 더 많은 세부 정보를 학습할 수 있지만, 계산 비용이 증가합니다. #크기를 줄이면 계산 비용은 감소하지만, 정보 손실로 인해 성능이 떨어질 수 있습니다.\n","LR = 1e-4       #학습률이 높으면 학습이 빠르게 진행되지만, 최적값을 놓치거나 불안정할 수 있습니다. #학습률이 낮으면 안정적으로 학습되지만, 시간이 오래 걸릴 수 있습니다.\n","EPOCHS = 10     #에포크 수가 많으면 모델이 데이터에 대해 더 잘 학습할 수 있지만, 과적합(overfitting)의 위험이 있습니다. #에포크 수가 적으면 과소적합(underfitting)이 발생할 수 있습니다.\n","BATCH_SIZE = 4  #배치 크기가 크면 학습이 안정적이고, GPU의 효율성을 높일 수 있습니다. 하지만 메모리 사용량이 증가합니다. #배치 크기가 작으면 메모리 사용량이 적고, 미세한 업데이트가 가능하지만, 학습이 불안정할 수 있습니다.\n","num_workers = 2 #작업자 수가 많으면 데이터 로딩 속도가 빨라져 학습이 더 원활하게 진행될 수 있습니다. #너무 많은 작업자를 사용하면 시스템의 다른 작업과 충돌하거나 메모리 문제가 발생할 수 있습니다."]},{"cell_type":"markdown","metadata":{"id":"amum-FlIojc6"},"source":["## 4. Load Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"llh5C7ZKoq2S"},"outputs":[],"source":["\"\"\"\n","# 데이터셋 경로 설정\n","dataset_path = Train_path\n","# 평균 및 표준편차 계산을 위한 변수 초기화\n","train_means = []\n","train_stds = []\n","# 이미지 경로에서 모든 이미지 파일을 읽어들임\n","image_files = [os.path.join(dataset_path, f) for f in os.listdir(dataset_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n","for image_file in image_files:\n","    # 이미지 로드 및 RGB로 변환\n","    image = cv2.imread(image_file)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    # 이미지의 평균 및 표준편차 계산\n","    train_means.append(np.mean(image, axis=(0, 1)) / 255.0)\n","    train_stds.append(np.std(image, axis=(0, 1)) / 255.0)\n","# 전체 데이터셋의 평균 및 표준편차 계산\n","train_mean = np.mean(train_means, axis=0)\n","train_std = np.mean(train_stds, axis=0)\n","print(f\"train_mean = {train_mean}\")\n","print(f\"train_std = {train_std}\")\n","\n","# 데이터셋 경로 설정\n","dataset_path = Test_path\n","# 평균 및 표준편차 계산을 위한 변수 초기화\n","test_means = []\n","test_stds = []\n","# 이미지 경로에서 모든 이미지 파일을 읽어들임\n","image_files = [os.path.join(dataset_path, f) for f in os.listdir(dataset_path) if f.endswith(('.png', '.jpg', '.jpeg'))]\n","for image_file in image_files:\n","    # 이미지 로드 및 RGB로 변환\n","    image = cv2.imread(image_file)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    # 이미지의 평균 및 표준편차 계산\n","    test_means.append(np.mean(image, axis=(0, 1)) / 255.0)\n","    test_stds.append(np.std(image, axis=(0, 1)) / 255.0)\n","# 전체 데이터셋의 평균 및 표준편차 계산\n","test_mean = np.mean(test_means, axis=0)\n","test_std = np.mean(test_stds, axis=0)\n","print(f\"test_mean = {test_mean}\")\n","print(f\"test_std = {test_std}\")\n","\"\"\"\n","\n","train_mean = [0.44537699, 0.44977048, 0.45193302]\n","train_std = [0.29171413, 0.29395023, 0.29496747]\n","test_mean = [0.44537699, 0.44977048, 0.45193302]\n","test_std = [0.29171413, 0.29395023, 0.29496747]\n","#test_mean = [0.49909188, 0.50301113, 0.50483625]\n","#test_std = [0.31717844, 0.31777685, 0.31768704]\n","\n","\n","# augmentation을 위한 transform 코드\n","trn_transform = A.Compose([\n","    A.Resize(height=img_size, width=img_size),\n","    A.Normalize(mean=train_mean, std=train_std),\n","    ToTensorV2()\n","])\n","\n","# test image 변환을 위한 transform 코드\n","tst_transform = A.Compose([\n","    A.Resize(height=img_size, width=img_size),\n","    A.Normalize(mean=test_mean, std=test_std),\n","    ToTensorV2()\n","])\n","\n","# 다시 확인하는데 걸리는 시간 :"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1722826909712,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"},"user_tz":-540},"id":"INxdmsStop2L","outputId":"82b85405-050f-4cac-829f-3710ef69f83b"},"outputs":[{"name":"stdout","output_type":"stream","text":["train dataset 개수: 48000   test dataset 개수: 3140\n","train 파일 개수: 48000  test 파일 개수: 3140\n"]}],"source":["# 디렉토리 내 파일 개수 확인\n","def count_files_in_directory(directory):  # 디렉토리 내 파일 목록 가져오기\n","    files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n","    return len(files)  # 파일 개수 반환\n","\n","# Dataset 정의\n","trn_dataset = ImageDataset(\n","    csv = Train_csv,\n","    path = Train_path,\n","    transform=trn_transform\n",")\n","tst_dataset = ImageDataset(\n","    Test_csv,\n","    Test_path,\n","    transform=tst_transform\n",")\n","\n","print(\"train dataset 개수:\", len(trn_dataset), \"  test dataset 개수:\", len(tst_dataset))\n","\n","file_count1 = count_files_in_directory(trn_dataset.path)  # 수정된 변수 사용\n","file_count2 = count_files_in_directory(tst_dataset.path)  # 수정된 변수 사용\n","print(f\"train 파일 개수: {file_count1}  test 파일 개수: {file_count2}\")\n","\n","\n","# DataLoader 정의\n","trn_loader = DataLoader(\n","    trn_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n","    num_workers=num_workers,\n","    pin_memory=True,\n","    drop_last=False\n",")\n","tst_loader = DataLoader(\n","    tst_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    num_workers=0,\n","    pin_memory=True\n",")"]},{"cell_type":"markdown","metadata":{"id":"Nmm5h3J-pXNV"},"source":["## 5. Train Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UfDOsgIJu-rp"},"outputs":[],"source":["import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1044,"status":"ok","timestamp":1722827051583,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"},"user_tz":-540},"id":"FbBgFPsLT-CO","outputId":"35bb2428-86b6-4515-fda8-7a8c0d7a5053"},"outputs":[{"name":"stdout","output_type":"stream","text":["model: swinv2_base_window12_192  |  img_size: 192  |  Learning Rate: 0.0001  |  EPOCHS: 10  |  BATCH_SIZE: 4  |  num_workers: 2\n"]}],"source":["# load model\n","model = timm.create_model(\n","    model_name,\n","    pretrained=True,\n","    num_classes=17\n",").to(device)\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = Adam(model.parameters(), lr=LR)\n","\n","print(f\"model: {model_name}  |  img_size: {img_size}  |  Learning Rate: {LR}  |  EPOCHS: {EPOCHS}  |  BATCH_SIZE: {BATCH_SIZE}  |  num_workers: {num_workers}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":426},"executionInfo":{"elapsed":10385,"status":"ok","timestamp":1722827066404,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"},"user_tz":-540},"id":"w2eIgoDHu-rq","outputId":"0458fc4f-d335-4007-b5ca-3493bf17ae72"},"outputs":[{"name":"stderr","output_type":"stream","text":["Loss: 0.5748:   0%|          | 59/12000 [00:08<27:14,  7.31it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","File \u001b[0;32m<timed exec>:16\u001b[0m\n","Cell \u001b[0;32mIn[33], line 15\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(loader, model, optimizer, loss_fn, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m targets \u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad(set_to_none\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 15\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(preds, targets)\n\u001b[1;32m     17\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/timm/models/swin_transformer_v2.py:612\u001b[0m, in \u001b[0;36mSwinTransformerV2.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    611\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 612\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    613\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_head(x)\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/timm/models/swin_transformer_v2.py:604\u001b[0m, in \u001b[0;36mSwinTransformerV2.forward_features\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_features\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    603\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch_embed(x)\n\u001b[0;32m--> 604\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n\u001b[1;32m    606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/timm/models/swin_transformer_v2.py:437\u001b[0m, in \u001b[0;36mSwinTransformerV2Stage.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    435\u001b[0m         x \u001b[38;5;241m=\u001b[39m checkpoint\u001b[38;5;241m.\u001b[39mcheckpoint(blk, x)\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 437\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/timm/models/swin_transformer_v2.py:322\u001b[0m, in \u001b[0;36mSwinTransformerV2Block.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    321\u001b[0m     B, H, W, C \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m--> 322\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_attn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[1;32m    323\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mreshape(B, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, C)\n\u001b[1;32m    324\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(x)))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/timm/models/swin_transformer_v2.py:307\u001b[0m, in \u001b[0;36mSwinTransformerV2Block._attn\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    304\u001b[0m x_windows \u001b[38;5;241m=\u001b[39m x_windows\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_area, C)  \u001b[38;5;66;03m# nW*B, window_size*window_size, C\u001b[39;00m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;66;03m# W-MSA/SW-MSA\u001b[39;00m\n\u001b[0;32m--> 307\u001b[0m attn_windows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_windows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn_mask\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# nW*B, window_size*window_size, C\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;66;03m# merge windows\u001b[39;00m\n\u001b[1;32m    310\u001b[0m attn_windows \u001b[38;5;241m=\u001b[39m attn_windows\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size[\u001b[38;5;241m1\u001b[39m], C)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/timm/models/swin_transformer_v2.py:188\u001b[0m, in \u001b[0;36mWindowAttention.forward\u001b[0;34m(self, x, mask)\u001b[0m\n\u001b[1;32m    184\u001b[0m     attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msoftmax(attn)\n\u001b[1;32m    186\u001b[0m attn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn_drop(attn)\n\u001b[0;32m--> 188\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mattn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(B_, N, C)\n\u001b[1;32m    189\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj(x)\n\u001b[1;32m    190\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproj_drop(x)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["%%time\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n","#브레이크\n","### 모델을 저장\n","# 메모리 가능 확인 기다리는 시간 30초\n","\n","#from torch.utils.tensorboard import SummaryWriter\n","\n","# TensorBoard SummaryWriter\n","#writer = SummaryWriter(log_dir='home/runs/exp1')\n","\n","save_dir = Model_path\n","os.makedirs(save_dir, exist_ok=True)\n","\n","for epoch in range(EPOCHS):\n","    ret = train_epoch(trn_loader, model, optimizer, loss_fn, device=device)  # train_epoch 함수를 호출하여 한 에포크 동안 모델을 학습시키고 결과를 반환받습니다.\n","    ret['epoch'] = epoch  # 반환된 결과 딕셔너리에 현재 에포크 번호를 추가합니다.\n","\n","    log = \"\"  # 로그 메시지를 저장할 문자열 변수를 초기화합니다.\n","    for k, v in ret.items():  # 결과 딕셔너리의 각 항목을 순회하면서 키와 값을 로그 문자열에 추가합니다.\n","        log += f\"{k}: {v:.4f}\\n\"  # 키와 값을 포맷팅하여 로그 문자열에 추가합니다.\n","    print(log)  # 완성된 로그 메시지를 출력합니다.\n","\n","    # 모델의 상태를 저장합니다.\n","    checkpoint_path = os.path.join(save_dir, f\"model_epoch_{epoch}.pth\")\n","    torch.save(model.state_dict(), checkpoint_path)\n","\n","    # TensorBoard에 기록합니다.\n","    #writer.add_scalar('Loss/train', ret['train_loss'], epoch)\n","    #writer.add_scalar('Accuracy/train', ret['train_acc'], epoch)\n","    #writer.add_scalar('F1_Score/train', ret['train_f1'], epoch)\n","\n","#writer.close()\"\"\""]},{"cell_type":"markdown","metadata":{"id":"uTsHQVKjM19u"},"source":["### Model 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QHQWh9A_M19u"},"outputs":[],"source":["# device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","# model config\n","model_name = 'swinv2_large_window12to24_192to384' # 'efficientnet_b5' #\n","\n","# 하이퍼파라미터를 설정합니다.\n","img_size = 384  #224 #크기를 늘리면 모델이 더 많은 세부 정보를 학습할 수 있지만, 계산 비용이 증가합니다. #크기를 줄이면 계산 비용은 감소하지만, 정보 손실로 인해 성능이 떨어질 수 있습니다.\n","LR = 1e-2       #학습률이 높으면 학습이 빠르게 진행되지만, 최적값을 놓치거나 불안정할 수 있습니다. #학습률이 낮으면 안정적으로 학습되지만, 시간이 오래 걸릴 수 있습니다.\n","EPOCHS = 5     #에포크 수가 많으면 모델이 데이터에 대해 더 잘 학습할 수 있지만, 과적합(overfitting)의 위험이 있습니다. #에포크 수가 적으면 과소적합(underfitting)이 발생할 수 있습니다.\n","BATCH_SIZE = 4  #배치 크기가 크면 학습이 안정적이고, GPU의 효율성을 높일 수 있습니다. 하지만 메모리 사용량이 증가합니다. #배치 크기가 작으면 메모리 사용량이 적고, 미세한 업데이트가 가능하지만, 학습이 불안정할 수 있습니다.\n","num_workers = 2 #작업자 수가 많으면 데이터 로딩 속도가 빨라져 학습이 더 원활하게 진행될 수 있습니다. #너무 많은 작업자를 사용하면 시스템의 다른 작업과 충돌하거나 메모리 문제가 발생할 수 있습니다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VxqzpdaGM19w"},"outputs":[],"source":["train_mean: [0.44537699, 0.44977048, 0.45193302]\n","train_std: [0.29171413, 0.29395023, 0.29496747]\n","test_mean = [0.49909188, 0.50301113, 0.50483625]\n","test_std: [0.31717844, 0.31777685, 0.31768704]\n","\n","\n","# augmentation을 위한 transform 코드\n","trn_transform = A.Compose([\n","    A.Resize(height=img_size, width=img_size),\n","    A.Normalize(mean=train_mean, std=train_std),\n","    ToTensorV2()\n","])\n","\n","# test image 변환을 위한 transform 코드\n","tst_transform = A.Compose([\n","    A.Resize(height=img_size, width=img_size),\n","    A.Normalize(mean=test_mean, std=test_std),\n","    ToTensorV2()\n","])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Occl2YNzM19w","outputId":"c0bfb0f3-106b-44c4-bf3e-3f50e69dce71"},"outputs":[{"name":"stdout","output_type":"stream","text":["train dataset 개수: 48000   test dataset 개수: 3140\n","train 파일 개수: 48000  test 파일 개수: 3140\n"]}],"source":["# 디렉토리 내 파일 개수 확인\n","def count_files_in_directory(directory):  # 디렉토리 내 파일 목록 가져오기\n","    files = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]\n","    return len(files)  # 파일 개수 반환\n","\n","# Dataset 정의\n","trn_dataset = ImageDataset(\n","    csv = Train_csv,\n","    path = Train_path,\n","    transform=trn_transform\n",")\n","tst_dataset = ImageDataset(\n","    Test_csv,\n","    Test_path,\n","    transform=tst_transform\n",")\n","\n","print(\"train dataset 개수:\", len(trn_dataset), \"  test dataset 개수:\", len(tst_dataset))\n","\n","file_count1 = count_files_in_directory(trn_dataset.path)  # 수정된 변수 사용\n","file_count2 = count_files_in_directory(tst_dataset.path)  # 수정된 변수 사용\n","print(f\"train 파일 개수: {file_count1}  test 파일 개수: {file_count2}\")\n","\n","\n","# DataLoader 정의\n","trn_loader = DataLoader(\n","    trn_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=True,\n","    num_workers=num_workers,\n","    pin_memory=True,\n","    drop_last=False\n",")\n","tst_loader = DataLoader(\n","    tst_dataset,\n","    batch_size=BATCH_SIZE,\n","    shuffle=False,\n","    num_workers=0,\n","    pin_memory=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cpvnHCCDM19w"},"outputs":[],"source":["# load model\n","model = timm.create_model(\n","    model_name,\n","    pretrained=True,\n","    num_classes=17\n",").to(device)\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = Adam(model.parameters(), lr=LR)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zZb1nvaIM19w","outputId":"dc81ca00-817b-460e-86bf-680ef9d67176"},"outputs":[{"name":"stderr","output_type":"stream","text":["Loss: 2.5411: 100%|██████████| 12000/12000 [1:29:38<00:00,  2.23it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train_loss: 2.9498\n","train_acc: 0.0681\n","train_f1: 0.0562\n","epoch: 0.0000\n","\n"]},{"name":"stderr","output_type":"stream","text":["Loss: 3.0206: 100%|██████████| 12000/12000 [1:29:36<00:00,  2.23it/s]\n"]},{"name":"stdout","output_type":"stream","text":["train_loss: 2.9185\n","train_acc: 0.0664\n","train_f1: 0.0557\n","epoch: 1.0000\n","\n"]},{"name":"stderr","output_type":"stream","text":["Loss: 3.2014:   2%|▏         | 211/12000 [01:35<1:28:30,  2.22it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","File \u001b[0;32m<timed exec>:16\u001b[0m\n","Cell \u001b[0;32mIn[10], line 17\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(loader, model, optimizer, loss_fn, device)\u001b[0m\n\u001b[1;32m     15\u001b[0m preds \u001b[38;5;241m=\u001b[39m model(image)\n\u001b[1;32m     16\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(preds, targets)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     20\u001b[0m train_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["%%time\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n","#브레이크\n","### 모델을 저장\n","# 메모리 가능 확인 기다리는 시간 30초\n","\n","#from torch.utils.tensorboard import SummaryWriter\n","\n","# TensorBoard SummaryWriter\n","#writer = SummaryWriter(log_dir='home/runs/exp1')\n","\n","save_dir = Model_path + \"swinv2_large_window12to24_192to384\"\n","os.makedirs(save_dir, exist_ok=True)\n","\n","for epoch in range(EPOCHS):\n","    ret = train_epoch(trn_loader, model, optimizer, loss_fn, device=device)  # train_epoch 함수를 호출하여 한 에포크 동안 모델을 학습시키고 결과를 반환받습니다.\n","    ret['epoch'] = epoch  # 반환된 결과 딕셔너리에 현재 에포크 번호를 추가합니다.\n","\n","    log = \"\"  # 로그 메시지를 저장할 문자열 변수를 초기화합니다.\n","    for k, v in ret.items():  # 결과 딕셔너리의 각 항목을 순회하면서 키와 값을 로그 문자열에 추가합니다.\n","        log += f\"{k}: {v:.4f}\\n\"  # 키와 값을 포맷팅하여 로그 문자열에 추가합니다.\n","    print(log)  # 완성된 로그 메시지를 출력합니다.\n","\n","    # 모델의 상태를 저장합니다.\n","    checkpoint_path = os.path.join(save_dir, f\"model_epoch_{epoch}.pth\")\n","    torch.save(model.state_dict(), checkpoint_path)\n","\n","    # TensorBoard에 기록합니다.\n","    #writer.add_scalar('Loss/train', ret['train_loss'], epoch)\n","    #writer.add_scalar('Accuracy/train', ret['train_acc'], epoch)\n","    #writer.add_scalar('F1_Score/train', ret['train_f1'], epoch)\n","\n","#writer.close()\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DuJUVE3kAWUd"},"outputs":[],"source":["#torch.cuda.empty_cache()\n","#!nvidia-smi"]},{"cell_type":"markdown","metadata":{"id":"lkwxRXoBpbaX"},"source":["# 6. Inference & Save File"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"aborted","timestamp":1722651610804,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"},"user_tz":-540},"id":"6V8Jg8FGu-rr","outputId":"227917f7-776c-466d-c12f-184fdb0025ab"},"outputs":[{"data":{"text/plain":["<All keys matched successfully>"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["# 브레이크\n","\n","### 저장된 모델 불러오기\n","\n","# 에포크 4에서 저장된 모델 파일 경로\n","epoch_to_load = 5\n","checkpoint_path = os.path.join(Model_path, f\"model_epoch_{epoch_to_load}.pth\")\n","\n","# 저장된 모델 상태를 불러옵니다\n","model.load_state_dict(torch.load(checkpoint_path))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"aborted","timestamp":1722651610804,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"},"user_tz":-540},"id":"uRYe6jlPU_Om","outputId":"efe2afb7-bfbc-4619-ee76-5baaf7a69cf2"},"outputs":[{"name":"stderr","output_type":"stream","text":["100%|██████████| 785/785 [00:39<00:00, 19.86it/s]\n"]}],"source":["\n","preds_list = []\n","\n","model.eval()\n","for image, _ in tqdm(tst_loader):\n","    image = image.to(device)\n","\n","    with torch.no_grad():\n","        preds = model(image)\n","    preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VDBXQqAzVvLY"},"outputs":[],"source":["pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])\n","pred_df['target'] = preds_list\n","\n","sample_submission_df = pd.read_csv(\"csv/sample_submission.csv\")\n","assert (sample_submission_df['ID'] == pred_df['ID']).all()\n","\n","pred_df.to_csv(\"csv/result_swin2_train_2_450\"+str(epoch_to_load)+\".csv\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MIkskdq8JY_m"},"outputs":[],"source":["# pred_df Macro F1 score 계산\n","#from sklearn.metrics import f1_score\n","#f1_score(sample_submission_df['target'], pred_df['target'], average='macro')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":10,"status":"aborted","timestamp":1722651610804,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"},"user_tz":-540},"id":"9yMO8s6GqAwZ","outputId":"326db085-fa65-4805-c476-f554a01cba57"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>ID</th>\n","      <th>target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0008fdb22ddce0ce.jpg</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>00091bffdffd83de.jpg</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>00396fbc1f6cc21d.jpg</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>00471f8038d9c4b6.jpg</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>00901f504008d884.jpg</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                     ID  target\n","0  0008fdb22ddce0ce.jpg       2\n","1  00091bffdffd83de.jpg      12\n","2  00396fbc1f6cc21d.jpg       5\n","3  00471f8038d9c4b6.jpg      13\n","4  00901f504008d884.jpg       2"]},"execution_count":138,"metadata":{},"output_type":"execute_result"}],"source":["pred_df.head(5)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ztW13IDZu-rt"},"outputs":[],"source":["pred_df['target'].value_counts()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GqR_S-fZu-rt"},"outputs":[],"source":["#ex = pred_df.reset_index()\n","\n","ex1 = pred_df.loc[pred_df['target'] == 0]\n","ex2 = pred_df.loc[pred_df['target'] != 0]"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1722651610804,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"},"user_tz":-540},"id":"VPIzU2Gtu-rt","outputId":"0e4ea013-fdec-432f-d8b6-4e4b7c321017"},"outputs":[{"name":"stdout","output_type":"stream","text":["                        ID  target\n","40    0412f6a5ba912add.jpg       0\n","57    05e33cb53c1ac02a.jpg       0\n","168   0f3bedf01f25f064.jpg       0\n","343   1dfce34ac940049d.jpg       0\n","439   267e2c2ec8182f3e.jpg       0\n","611   35131e3f1dc21609.jpg       0\n","616   3551ff70a2ee733b.jpg       0\n","821   43f11f0c5245ccb9.jpg       0\n","938   4f48d6bc2d3af344.jpg       0\n","1118  5eba163f304ef235.jpg       0\n","1123  5f0e93a989259358.jpg       0\n","1147  613ee74ac4a149c1.jpg       0\n","1226  670e484e9f4d4000.jpg       0\n","1269  6aa1e9befa8af3f8.jpg       0\n","1710  8f307c4c9f0ec2f8.jpg       0\n","1784  95c6c1c9dd14cad3.jpg       0\n","1904  9e32d5c65c99feac.jpg       0\n","1923  9f5b1c60ab6753cb.jpg       0\n","2007  a67caaccc2ea8ab2.jpg       0\n","2278  bbaec8719d4109d0.jpg       0\n","2375  c5c6626a8c92d45a.jpg       0\n","2405  c7fe39e0b08a84c4.jpg       0\n","2490  cf1937be84a9ba49.jpg       0\n","2548  d30cca5a80ea5a72.jpg       0\n","2556  d394c42a267a320b.jpg       0\n","2620  d86b9af8c6e19923.jpg       0\n","2705  de6ecb4369bfa015.jpg       0\n","2746  e1924ae57aaee6f7.jpg       0\n","2859  ea1f0cc81ab2fa91.jpg       0\n","2896  ed98089419468d13.jpg       0\n","3008  f652c12e67c66c6f.jpg       0\n","3040  f87fdd6c08a4fb1f.jpg       0\n","3050  f93a97c7503a74bb.jpg       0                         ID  target\n","0     0008fdb22ddce0ce.jpg       9\n","1     00091bffdffd83de.jpg      10\n","2     00396fbc1f6cc21d.jpg       8\n","3     00471f8038d9c4b6.jpg       4\n","4     00901f504008d884.jpg       9\n","...                    ...     ...\n","3135  ffb4b6f619fb60ea.jpg      12\n","3136  ffb54299b1ad4159.jpg       3\n","3137  ffc2c91dff8cf2c0.jpg       3\n","3138  ffc4e330a5353a2a.jpg      10\n","3139  ffc71fed753d90c1.jpg      12\n","\n","[3107 rows x 2 columns]\n"]}],"source":["print(ex1, ex2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"loa0Taqnu-rt"},"outputs":[],"source":["ex1.to_csv('/home/step1.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uRnnwYZRJY_m"},"outputs":[],"source":["# 1부터 17까지의 숫자로 폴더 생성\n","for i in range(0, 17):\n","    folder_name = str(i)\n","    folder_path = os.path.join('/home/data/cl/', folder_name)\n","    os.makedirs(folder_path, exist_ok=True)\n","    #print(f\"폴더 생성: {folder_path}\")\n","\n","class_df = pred_df\n","\n","for i in range(0, len(class_df)) :\n","    print(class_df['ID'][i], class_df['target'][i] )\n","    img = cv2.imread('/home/data/test2x/' + class_df['ID'][i])\n","    cv2.imwrite('/home/data/cl/' + str(class_df['target'][i]) + '/' + class_df['ID'][i], img)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1722651610804,"user":{"displayName":"Donggun Lim","userId":"16228281816473625159"},"user_tz":-540},"id":"sUzpZ97hJY_m","outputId":"a6c51416-057c-42e3-dbca-c78eef71b7c0"},"outputs":[{"name":"stdout","output_type":"stream","text":["비교할 파일 주소\n","csv/result_swin2_train_2_4505.csv\n","csv/answer.csv\n","데이터 간 다른 항목수 : 558  / 3140\n","데이터 중 맞은 퍼센트 : 82.22929936305732\n"]}],"source":["### 데이터셋 결과 비교\n","\n","filename = \"result_swin2_train_2_450\" + str(epoch_to_load)\n","\n","# 데이터셋 로드\n","a_path = 'csv/' + str(filename) + '.csv'\n","b_path = 'csv/answer.csv'\n","\n","a_df = pd.read_csv(a_path)\n","b_df = pd.read_csv(b_path)\n","\n","# a_df.shape, b_df.shape:\n","\n","b_df = b_df.drop(columns=['Unnamed: 0'])\n","\n","print(\"비교할 파일 주소\")\n","print(a_path)\n","print(b_path)\n","\n","# 두 데이터프레임의 크기가 같은지 확인\n","if a_df.shape != b_df.shape:\n","    raise ValueError(\"두 데이터프레임의 크기가 다릅니다.\")\n","\n","# 두 데이터프레임의 각 셀을 비교\n","comparison = a_df != b_df\n","\n","# 다른 항목의 개수를 계산\n","difference_count = comparison.sum().sum()\n","\n","#print(comparison)\n","\n","print(f\"데이터 간 다른 항목수 : {difference_count}  / 3140\")\n","\n","print(f\"데이터 중 맞은 퍼센트 : {(3140 - difference_count) / 3140 * 100}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g2QkquMuM194"},"outputs":[],"source":["비교할 파일 주소\n","csv/result_swin2_train_2_4509.csv\n","csv/answer.csv\n","데이터 간 다른 항목수 : 655  / 3140\n","데이터 중 맞은 퍼센트 : 79.14012738853503\n","\n","비교할 파일 주소\n","csv/result_swin2_train_2_4505.csv\n","csv/answer.csv\n","데이터 간 다른 항목수 : 558  / 3140\n","데이터 중 맞은 퍼센트 : 82.22929936305732"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"velMyeDTM194","outputId":"20a40661-0c34-488e-8023-094bd9b5e6cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["-257.79399999999987\n"]}],"source":["a=(0.9179*3140)-3140\n","print(a)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AH0nO8QEM194"},"outputs":[],"source":["비교할 파일 주소\n","csv/result_1_padding.csv   #ep3임\n","csv/answer.csv\n","3140 rows x 2 columns]\n","데이터 간 다른 항목수 : 369  / 3140\n","데이터 중 맞은 퍼센트 : 88.2484076433121\n","epoch 3.0\n","\n","\n","비교할 파일 주소\n","csv/result_1_padding_ep2.csv\n","csv/answer.csv\n","[3140 rows x 2 columns]\n","데이터 간 다른 항목수 : 373  / 3140\n","데이터 중 맞은 퍼센트 : 88.12101910828025\n","\n","\n","비교할 파일 주소\n","csv/result_1_padding_ep4.csv\n","csv/answer.csv\n","[3140 rows x 2 columns]\n","데이터 간 다른 항목수 : 333  / 3140\n","데이터 중 맞은 퍼센트 : 89.39490445859872"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y5gvb5QhM194"},"outputs":[],"source":["비교할 파일 주소\n","csv/result_2_bc_ep2.csv\n","csv/answer.csv\n","[3140 rows x 2 columns]\n","데이터 간 다른 항목수 : 374  / 3140\n","데이터 중 맞은 퍼센트 : 88.0891719745223\n","\n","비교할 파일 주소\n","csv/result_2_bc_ep3.csv\n","csv/answer.csv\n","[3140 rows x 2 columns]\n","데이터 간 다른 항목수 : 333  / 3140\n","데이터 중 맞은 퍼센트 : 89.39490445859872\n","\n","비교할 파일 주소\n","csv/result_2_bc_ep4.csv\n","csv/answer.csv\n","데이터 간 다른 항목수 : 320  / 3140\n","데이터 중 맞은 퍼센트 : 89.80891719745223\n","\n","비교할 파일 주소\n","csv/result_2_bc_ep5.csv\n","csv/answer.csv\n","데이터 간 다른 항목수 : 386  / 3140\n","데이터 중 맞은 퍼센트 : 87.70700636942675\n","\n","비교할 파일 주소\n","csv/result_2_bc_ep6.csv\n","csv/answer.csv\n","데이터 간 다른 항목수 : 330  / 3140\n","데이터 중 맞은 퍼센트 : 89.49044585987261\n","\n","비교할 파일 주소\n","csv/result_2_bc_ep7.csv\n","csv/answer.csv\n","데이터 간 다른 항목수 : 314  / 3140\n","데이터 중 맞은 퍼센트 : 90.0 = 9179\n","\n","비교할 파일 주소\n","csv/result_2_bc_ep8.csv\n","csv/answer.csv\n","데이터 간 다른 항목수 : 410  / 3140\n","데이터 중 맞은 퍼센트 : 86.94267515923568\n","\n","비교할 파일 주소\n","csv/result_2_bc_ep9.csv\n","csv/answer.csv\n","데이터 간 다른 항목수 : 373  / 3140\n","데이터 중 맞은 퍼센트 : 88.12101910828025"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1zqAlvckm4j-Z-olX-v8jLKh_Y78NP2zz","timestamp":1722334702584}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}